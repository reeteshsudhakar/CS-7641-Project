{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.impute import KNNImputer\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path: data-processing.ipynb\n",
    "# Read in the data\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes columns we first deemed are useless\n",
    "util.defaultClean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns with NaNs\n",
    "df2 = df.loc[:, df.isnull().any()]\n",
    "print(\"numCols: \", len(df2.columns))\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates percentage of NaNs alongside data type of column\n",
    "percentNull = {}\n",
    "for col in df.columns:\n",
    "    percent = (len(df[df[col].isnull()]))/len(df)\n",
    "    if percent > 0:\n",
    "        percentNull[col] = (df.dtypes[col], percent)\n",
    "percentNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows all rows where a certain column has NaNs\n",
    "df[df['EXT_SOURCE_2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y'ALL, WE'RE DUMB AS SHIT. Check this out:\n",
    "col_descriptions = pd.read_csv('data/HomeCredit_columns_description.csv', encoding = \"ISO-8859-1\")\n",
    "col_descriptions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name | DType | What it Means | How to Handle |\n",
    "| --- | --- | --- | --- |\n",
    "| AMT_ANNUITY | float | Monthly payment for the loan | I would find the mean of AMT_ANNUITY/AMT_CREDIT and then multiply that mean ratio by the AMT_CREDIT for the rows that don't have a NaN AMT_ANNUITY |\n",
    "| AMT_GOODS_PRICE | float | Price of the Good that people get a loan for | Most times, AMT_CREDIT is either slightly greater than or equal to AMT_GOODS_PRICE, so I would just set NaNs in AMT_GOODS_PRICE to whatever the AMT_CREDIT is for that row|\n",
    "| NAME_TYPE_SUITE | String | Who was accompanying the person when they were applying for the loan | Either just assume they were unnacompanied, use the mode, or use K-Means |\n",
    "| OWN_CAR_AGE | float | Age of the car they owned | Fill NaNs w/ 0 or -1, since a person without a car will have a NaN here. Filling with 0 as it could conflate with those who have a brand new car, but -1 could be mistinterpreted as a very very new car or something |\n",
    "| OCCUPATION_TYPE | String | What the person's occupation is | Not sure, probably should leave to K-Means |\n",
    "| CNT_FAM_MEMBERS | float | How many family members the person has | K-Means or mode |\n",
    "| EXT_SOURCE_1 | float | Normalized score from external database | Linear Regression/Use other two scores. There are situations in which only one score is present, and very few where no external scores are present. |\n",
    "| EXT_SOURCE_2 | float | Normalized score from external database | Linear Regression/Use other two scores. There are situations in which only one score is present, and very few where no external scores are present. |\n",
    "| EXT_SOURCE_3 | float | Normalized score from external database | Linear Regression/Use other two scores. There are situations in which only one score is present, and very few where no external scores are present. |\n",
    "| OBS_30_CNT_SOCIAL_CIRCLE | float | Amount of people in person's social circle who were observed with a possible 30 DPD (Days past due) default | NaN means there was no observation, so I would make an \"assumption\" of 0, but you could also use K-Means I think |\n",
    "| DEF_30_CNT_SOCIAL_CIRCLE | float | Amount of people in person's social circle who defaulted with a  30 DPD (Days past due) | NaN means there was no observation, so I would make an \"assumption\" of 0, but you could also use K-Means I think |\n",
    "| OBS_60_CNT_SOCIAL_CIRCLE | float | Amount of people in person's social circle who were observed with a possible 60 DPD (Days past due) default | NaN means there was no observation, so I would make an \"assumption\" of 0, but you could also use K-Means I think |\n",
    "| DEF_60_CNT_SOCIAL_CIRCLE | float | Amount of people in person's social circle who defaulted with a 60 DPD (Days past due) | NaN means there was no observation, so I would make an \"assumption\" of 0, but you could also use K-Means I think |\n",
    "| DAYS_LAST_PHONE_CHANGE | float | How many days before applying did the client change their phone | I think there's only one NaN so we can set it to 0 |\n",
    "| AMT_REQ_CREDIT_BUREAU_HOUR | float | Amount of enquiries the client had with the Credit Bureau one hour before application | If there's no data, we probably should assume 0. We can't really guess at how many enquiries a client had and when they had them |\n",
    "| AMT_REQ_CREDIT_BUREAU_DAY | float | Amount of enquiries the client had with the Credit Bureau one day before application | If there's no data, we probably should assume 0. We can't really guess at how many enquiries a client had and when they had them |\n",
    "| AMT_REQ_CREDIT_BUREAU_WEEK | float | Amount of enquiries the client had with the Credit Bureau one week before application | If there's no data, we probably should assume 0. We can't really guess at how many enquiries a client had and when they had them |\n",
    "| AMT_REQ_CREDIT_BUREAU_MON | float | Amount of enquiries the client had with the Credit Bureau one month before application | If there's no data, we probably should assume 0. We can't really guess at how many enquiries a client had and when they had them |\n",
    "| AMT_REQ_CREDIT_BUREAU_QRT | float | Amount of enquiries the client had with the Credit Bureau three months before application | If there's no data, we probably should assume 0. We can't really guess at how many enquiries a client had and when they had them |\n",
    "| AMT_REQ_CREDIT_BUREAU_YEAR | float | Amount of enquiries the client had with the Credit Bureau one year before application | If there's no data, we probably should assume 0. We can't really guess at how many enquiries a client had and when they had them |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80/20 train-test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, test_df = model_selection.train_test_split(df, test_size=0.2, shuffle=True)\n",
    "print(\"training size:\", len(df))\n",
    "print(\"testing size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows where AMT_ANNUITY is NaN\n",
    "df_annuity = df[df[\"AMT_ANNUITY\"].notnull()]\n",
    "# Average of non NaN AMT_ANNUITY\n",
    "numerator = df_annuity[\"AMT_ANNUITY\"].mean()\n",
    "# Average of non NaN AMT_CREDIT\n",
    "denominator = df_annuity[\"AMT_CREDIT\"].mean()\n",
    "# Average ratio of AMT_ANNUITY / AMT_CREDIT\n",
    "ratio = numerator / denominator\n",
    "# Set Nulls in AMT_ANNUITY to ratio multiplied by the relevant AMT_CREDIT index\n",
    "df[\"AMT_ANNUITY\"] = df[\"AMT_ANNUITY\"].fillna(ratio * df[\"AMT_CREDIT\"])\n",
    "\n",
    " # Set Nulls in AMT_GOODS_PRICE to the relevant AMT_CREDIT index\n",
    "df[\"AMT_GOODS_PRICE\"] = df[\"AMT_GOODS_PRICE\"].fillna(df[\"AMT_CREDIT\"])\n",
    "\n",
    "# Columns where we fill null with 0\n",
    "cols = [\"OWN_CAR_AGE\", \"OBS_30_CNT_SOCIAL_CIRCLE\", \"DEF_30_CNT_SOCIAL_CIRCLE\",\n",
    "        \"OBS_60_CNT_SOCIAL_CIRCLE\", \"DEF_60_CNT_SOCIAL_CIRCLE\", \"DAYS_LAST_PHONE_CHANGE\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_HOUR\", \"AMT_REQ_CREDIT_BUREAU_DAY\", \"AMT_REQ_CREDIT_BUREAU_WEEK\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_MON\", \"AMT_REQ_CREDIT_BUREAU_QRT\", \"AMT_REQ_CREDIT_BUREAU_YEAR\"]\n",
    "# Set Nulls in cols to 0\n",
    "for col in cols:\n",
    "        df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=3)\n",
    "knn_imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_ext_df =  df.dropna(subset=['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3'])\n",
    "# non_null_ext_df = df.fillna(value={'EXT_SOURCE_1': 0.5, 'EXT_SOURCE_2': 0.5, 'EXT_SOURCE_3': 0.5})\n",
    "print(non_null_ext_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']])\n",
    "print(\"# points that have all 3 non-null ext sources:\", len(non_null_ext_df))\n",
    "non_null_ext_sample = non_null_ext_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sample(frac=0.001)\n",
    "# extsrc_regr = linear_model.LinearRegression().fit()\n",
    "ext_src_fig = px.scatter_3d(non_null_ext_sample, x='EXT_SOURCE_1', y='EXT_SOURCE_2', z='EXT_SOURCE_3')\n",
    "ext_src_fig.show()\n",
    "print(\"correlation between sources 1 and 2 compared to source2\\n\",\n",
    "      non_null_ext_df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].corr()['EXT_SOURCE_2'][:], sep='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
