{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.impute import SimpleImputer\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path: data-processing.ipynb\n",
    "# Read in the data\n",
    "df = pd.read_csv('data/application_train.csv')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes columns we first deemed are useless\n",
    "util.defaultClean(df)\n",
    "target = df[\"TARGET\"]\n",
    "df.drop(columns = [\"TARGET\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv('data/bureau.csv')\n",
    "bureau = bureau[bureau[\"CREDIT_CURRENCY\"] == \"currency 1\"]\n",
    "bureau.drop(columns = [\"SK_ID_BUREAU\", \"CREDIT_ACTIVE\", \"CREDIT_CURRENCY\", \"DAYS_CREDIT\", \"CREDIT_DAY_OVERDUE\", \"DAYS_CREDIT_ENDDATE\", \"DAYS_ENDDATE_FACT\", \"CREDIT_TYPE\", \"DAYS_CREDIT_UPDATE\", \"AMT_ANNUITY\"], inplace=True)\n",
    "bureau.fillna(0, inplace=True)\n",
    "bureau[\"CREDIT_BUREAU_APPLICATION_COUNT\"] = 1\n",
    "bureau.sort_values(by=[\"SK_ID_CURR\"], inplace=True)\n",
    "bureau = bureau.groupby(\"SK_ID_CURR\").mean()\n",
    "df = df.merge(bureau, how=\"left\", on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = pd.read_csv('data/previous_application.csv')\n",
    "prev.drop(columns=[\"SK_ID_PREV\", \"NAME_CONTRACT_TYPE\", \"WEEKDAY_APPR_PROCESS_START\", \"HOUR_APPR_PROCESS_START\", \"FLAG_LAST_APPL_PER_CONTRACT\", \"NFLAG_LAST_APPL_IN_DAY\",\n",
    "                   \"AMT_DOWN_PAYMENT\", \"AMT_GOODS_PRICE\", \"RATE_INTEREST_PRIMARY\", \"RATE_INTEREST_PRIVILEGED\",\n",
    "                   \"NAME_CASH_LOAN_PURPOSE\", \"DAYS_DECISION\", \"NAME_TYPE_SUITE\", \"NAME_GOODS_CATEGORY\", \"NAME_PORTFOLIO\", \"NAME_PRODUCT_TYPE\", \"CHANNEL_TYPE\", \"SELLERPLACE_AREA\", \"NAME_SELLER_INDUSTRY\", \"CNT_PAYMENT\",\n",
    "                   \"PRODUCT_COMBINATION\", \"DAYS_FIRST_DRAWING\", \"DAYS_FIRST_DUE\", \"DAYS_LAST_DUE_1ST_VERSION\", \"DAYS_LAST_DUE\", \"DAYS_TERMINATION\"], inplace=True)\n",
    "prev = prev[prev[\"NAME_CONTRACT_STATUS\"] != \"Canceled\"]\n",
    "prev.fillna(0, inplace=True)\n",
    "prev[\"TIME_TO_PAY\"] = prev[\"AMT_CREDIT\"] / prev[\"AMT_ANNUITY\"]\n",
    "prev[\"AMT_CREDIT\"] = np.where(prev[\"NAME_CONTRACT_STATUS\"] == \"Refused\", 0, prev[\"AMT_CREDIT\"])\n",
    "prev[\"CREDIT_DIFFERENCE\"] = prev[\"AMT_CREDIT\"] - prev[\"AMT_APPLICATION\"]\n",
    "prev.drop(columns=[\"AMT_ANNUITY\", \"AMT_APPLICATION\", \"AMT_CREDIT\"], inplace=True)\n",
    "\n",
    "str_columns = prev.select_dtypes(['string', \"object\"]).columns\n",
    "prev[str_columns] = prev[str_columns].astype(\"category\")\n",
    "cat_columns = prev.select_dtypes(['category']).columns\n",
    "prev = util.onehot_categorical_columns(prev, cat_columns)\n",
    "prev.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "prev1 = prev[[\"SK_ID_CURR\", \"RATE_DOWN_PAYMENT\", \"NFLAG_INSURED_ON_APPROVAL\", \"TIME_TO_PAY\", \"CREDIT_DIFFERENCE\"]]\n",
    "prev2 = prev.drop(columns=[\"RATE_DOWN_PAYMENT\", \"NFLAG_INSURED_ON_APPROVAL\", \"TIME_TO_PAY\", \"CREDIT_DIFFERENCE\"])\n",
    "prev1 = prev1.groupby(\"SK_ID_CURR\").agg(\n",
    "    AVG_DOWN_PAYMENT=pd.NamedAgg(column=\"RATE_DOWN_PAYMENT\", aggfunc=\"mean\"),\n",
    "    NUM_INSURED=pd.NamedAgg(column=\"NFLAG_INSURED_ON_APPROVAL\", aggfunc=\"sum\"),\n",
    "    AVG_MONTHS_TO_PAY=pd.NamedAgg(column=\"TIME_TO_PAY\", aggfunc=\"mean\"),\n",
    "    TOTAL_CREDIT_DIFFERENCE=pd.NamedAgg(column=\"CREDIT_DIFFERENCE\", aggfunc=\"sum\"),\n",
    ")\n",
    "prev2 = prev2.groupby(\"SK_ID_CURR\").sum()\n",
    "prev = prev1.merge(prev2, how=\"inner\", on=\"SK_ID_CURR\")\n",
    "df = df.merge(prev, how=\"left\", on=\"SK_ID_CURR\")\n",
    "df.head(15)\n",
    "# prev.sort_values(by=[\"SK_ID_CURR\"], inplace=True)\n",
    "# prev[\"NAME_CONTRACT_STATUS\"].value_counts(normalize=True)\n",
    "# prev.head(15)\n",
    "# prev[prev[\"NAME_CONTRACT_STATUS\"] == \"Unused offer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"SK_ID_CURR\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns with NaNs\n",
    "df2 = df.loc[:, df.isnull().any()]\n",
    "print(\"numCols: \", len(df2.columns))\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates percentage of NaNs alongside data type of column\n",
    "percentNull = {}\n",
    "for col in df.columns:\n",
    "    percent = (len(df[df[col].isnull()]))/len(df)\n",
    "    if percent > 0:\n",
    "        percentNull[col] = (df.dtypes[col], percent)\n",
    "percentNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows all rows where a certain column has NaNs\n",
    "df[df['EXT_SOURCE_2'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y'ALL, WE'RE DUMB AS SHIT. Check this out:\n",
    "col_descriptions = pd.read_csv('data/HomeCredit_columns_description.csv', encoding = \"ISO-8859-1\")\n",
    "col_descriptions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All rows where AMT_ANNUITY is NaN\n",
    "df_annuity = df[df[\"AMT_ANNUITY\"].notnull()]\n",
    "# Average of non NaN AMT_ANNUITY\n",
    "numerator = df_annuity[\"AMT_ANNUITY\"].mean()\n",
    "# Average of non NaN AMT_CREDIT\n",
    "denominator = df_annuity[\"AMT_CREDIT\"].mean()\n",
    "# Average ratio of AMT_ANNUITY / AMT_CREDIT\n",
    "ratio = numerator / denominator\n",
    "# Set Nulls in AMT_ANNUITY to ratio multiplied by the relevant AMT_CREDIT index\n",
    "df[\"AMT_ANNUITY\"] = df[\"AMT_ANNUITY\"].fillna(ratio * df[\"AMT_CREDIT\"])\n",
    "\n",
    " # Set Nulls in AMT_GOODS_PRICE to the relevant AMT_CREDIT index\n",
    "df[\"AMT_GOODS_PRICE\"] = df[\"AMT_GOODS_PRICE\"].fillna(df[\"AMT_CREDIT\"])\n",
    "\n",
    "# Columns where we fill null with 0\n",
    "zero_cols = [\"OWN_CAR_AGE\", \"DAYS_LAST_PHONE_CHANGE\", \"AMT_REQ_CREDIT_BUREAU_HOUR\", \"AMT_REQ_CREDIT_BUREAU_DAY\", \"AMT_REQ_CREDIT_BUREAU_WEEK\",\n",
    "        \"AMT_REQ_CREDIT_BUREAU_MON\", \"AMT_REQ_CREDIT_BUREAU_QRT\", \"AMT_REQ_CREDIT_BUREAU_YEAR\"]\n",
    "# Set Nulls in zero cols to 0\n",
    "for col in zero_cols:\n",
    "        df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_columns = df.select_dtypes(['string', \"object\"]).columns\n",
    "df[str_columns] = df[str_columns].astype(\"category\")\n",
    "cat_columns = df.select_dtypes(['category']).columns\n",
    "# df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes + 1)\n",
    "df = util.onehot_categorical_columns(df, cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.NaN, strategy = \"constant\", fill_value=0)\n",
    "df[:] = imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_feature_importance import get_feature_imp\n",
    "# get_feature_imp(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = util.run_pca(df, 200)\n",
    "# output = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(output.to_numpy(), target.to_numpy(), test_size=0.25, shuffle=True, stratify=target.to_numpy())\n",
    "print(\"training size:\", len(train_X))\n",
    "print(\"testing size:\", len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import run_and_compare\n",
    "run_and_compare(train_X, train_y, test_X, test_y, model='svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Accuracies\n",
    "\n",
    "Note that these will probably be slightly different each time based on the data split. I just wrote these down for a general idea of the best params. \n",
    "\n",
    "200 components: \n",
    "- Hinge — 0.6432888166607337\n",
    "- log_loss — 0.6371600030709288\n",
    "- huber — 0.6045798030541624\n",
    "- epsilon_insensitive -- 0.6243449925510459\n",
    "- modified_huber — 0.6607661267904723\n",
    "- squared_hinge — 0.6525500834455048\n",
    "- perceptron — 0.5963679298868061 (really good for 0s, but probably because it might just be guessing 0s a ton and getting a high hit rate) \n",
    "\n",
    "175 components:\n",
    "- Hinge — 0.6468060525314879\n",
    "- log_loss — 0.6172351771686619\n",
    "- huber — 0.6247846510249453\n",
    "- epsilon_insensitive -- 0.6245843411376562\n",
    "    - Did a great job predicting defaults (0.84) \n",
    "- modified_huber — 0.6557343207158701\n",
    "- squared_hinge — 0.5492138711315983\n",
    "- perceptron — 0.5041903878103752 (lol now I KNOW this shit is just guessing 1)\n",
    "\n",
    "150 components: \n",
    "- Hinge — 0.6453322424507427\n",
    "- log_loss — 0.591766431876927\n",
    "- huber — 0.61793966358117\n",
    "- epsilon_insensitive -- 0.6354215862146304\n",
    "    - Did a great job predicting defaults (0.78) \n",
    "- modified_huber — 0.6425852080603528\n",
    "- squared_hinge — 0.5466302351985645\n",
    "- perceptron — 0.6012018087070353\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import run_and_compare\n",
    "run_and_compare(train_X, train_y, test_X, test_y, model='lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Accuracies:\n",
    "\n",
    "Note that these will probably be slightly different each time based on the data split. I just wrote these down for a general idea of the best params. \n",
    "\n",
    "150 Components:\n",
    "- C 0.25 — 0.6628742530343206\n",
    "- C 0.5 — 0.6681524393126752\n",
    "- C 0.75 — 0.6702277034625324\n",
    "- C 1 — 0.6721468834960813\n",
    "- C 1.25 — 0.6723835348054287\n",
    "- C 1.5 — 0.6737241591262073\n",
    "- C 1.75 — 0.6741726230817547\n",
    "- C 2 — 0.6736864770456279\n",
    "- C 5 — 0.6760685536341112\n",
    "- C 10 — 0.6752884385767906\n",
    "- C 50 — 0.6750325871221924\n",
    "\n",
    "200 Components:\n",
    "- C 0.25 — 0.6663838348393336\n",
    "- C 0.5 — 0.6710626760777125\n",
    "- C 0.75 — 0.6734488020021376\n",
    "- C 1 — 0.6737931665595478\n",
    "- C 1.25 — 0.6733738733269949\n",
    "- C 1.5 — 0.6753873349430477\n",
    "- C 1.75 — 0.6755968401973712\n",
    "- C 2 — 0.6757949384541065\n",
    "- C 5 — 0.6754746943499215\n",
    "- C 10 — 0.6759695045057436\n",
    "- C 50 — 0.6751665754532465\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
